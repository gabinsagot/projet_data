{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PC 4 : Apprentissage supervisé et prétraitement - 23 juin 2025 - Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce notebook, nous allons explorer quelques méthodes de prétraitement des données et leur impact sur une régression linéaire. \n",
    "\n",
    "Ce notebook vous permettra ainsi de découvrir des fonctionalités de `scikit-learn` permettant :\n",
    "* d'entrainer et évaluer un algorithme d'apprentissage supervisé\n",
    "* d'encoder des variables qualitatives ;\n",
    "* de ramener des variables à une fourchette de valeurs ;\n",
    "* de transformer des variables pour rapprocher leur distribution de celle d'une gaussienne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('font', **{'size': 12}) # règle la taille de police globalement pour les plots (en pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Données\n",
    "Dans ce notebook nous allons travailler avec les données contenues dans le fichier `../../data/auto-mpg.tsv`. Ces données, obtenues sur https://archive.ics.uci.edu/ml/datasets/Auto+MPG, décrivent des voitures par les variables suivantes :\n",
    "\n",
    "    1. mpg:           consommation (en miles par gallon), continue\n",
    "    2. cylinders:     nombre de cylindres, discrète\n",
    "    3. displacement:  cylindrée, continue\n",
    "    4. horsepower:    chevaux-vapeur, continue\n",
    "    5. weight:        poids, continue\n",
    "    6. acceleration:  accélération, continue\n",
    "    7. model year:    année, discrète\n",
    "    8. origin:        région d'origine, discrète (1=Amérique du Nord ; 2=Europe ; 3=Asie)\n",
    "    9. car name:      nom, chaîne de caractères."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre but va être de prédire la consommation d'un véhicule à partir des autres variables (à l'exclusion du nom de la voiture, qui est un identifiant unique)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les données\n",
    "df = pd.read_csv(\"data/auto-mpg.tsv\", delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création des matrices X et y de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df.drop(columns=['mpg', 'car name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(df['mpg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Séparation en un jeu d'entraînement et un jeu de test\n",
    "\n",
    "Notre but étant de construire un modèle prédictif, nous allons pour l'évaluer mettre de côté une partie des données (20%), le jeu de test, que nous n'utiliserons pas pour l'entraînement. Rappelez-vous que la minimisation du risque empirique ne garantit pas la minimisation du risque : la performance d'un modèle sur les données sur lesquelles il est entraîné peut être excellente, sans que celui-ci fasse de bonnes prédictions sur d'autres individus. Vous pouvez comparer ça à apprendre par cœur le jeu d'entraînement. Nous parlerons plus en détail de sélection et évaluation de modèle au chapitre 8. \n",
    "\n",
    "L'utilisation de l'argument `random_state` garantit que la répartition des individus entre les deux jeux soit toujours la même au sein de ce notebook si vous relancez la commande. Attention, vous n'aurez a priori pas la même que quelqu'un d'autre exécutant le même notebook sur une autre machine, ce qui peut expliquer de fluctuations entre vos résultats et ceux d'une autre personne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, \n",
    "                                                                    test_size=0.20, \n",
    "                                                                    random_state=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Combien d'observations et de variables contiennent, respectivement, le jeu d'échantillon et le jeu de test ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ Le jeu d'entraînement contient 313 échantillons. Le jeu de test en contient 79. Les données sont représentées par 7 variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualisation des données\n",
    "\n",
    "Nous allons maintenant visualiser les variables représentant nos véhicules. Pour ce faire, nous allons séparer les variables continues (que nous allons représenter chacune par un histogramme) des variables discrètes (que nous allons représenter chacune par un diagramme en barre).\n",
    "\n",
    "Nous nous concentrons sur le jeu d'entraînement : notre but est d'utiliser le jeu de test pour tester les modèles appris sur le jeu d'entraînement, en prétendant ne pas le connaître au moment de l'entraînement.\n",
    "\n",
    "N'hésitez pas à ajuster les paramètres des méthodes de `matplotlib` pour produire des graphiques plus lisibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_features = ['displacement', 'horsepower', 'weight', 'acceleration']\n",
    "discrete_features = ['cylinders', 'model year', 'origin']\n",
    "\n",
    "features = list(df.drop(columns=['mpg', 'car name']).columns)\n",
    "\n",
    "continuous_features_idx = [features.index(feat_name) for feat_name in continuous_features]\n",
    "discrete_features_idx = [features.index(feat_name) for feat_name in discrete_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant représenter les variables discrètes par des diagrammes en barres :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagramme en barres pour les variables discrètes\n",
    "fig = plt.figure(figsize=(12, 3))\n",
    "\n",
    "for (plot_idx, feat_idx) in enumerate(discrete_features_idx):\n",
    "    # créer une sous-figure (subplot) à la position (plot_idx+1) d'une grille 1x3\n",
    "    ax = fig.add_subplot(1, 3, (plot_idx+1))\n",
    "\n",
    "    # calculer la fréquence de chacune des valeurs prise par la variable feat_idx\n",
    "    feature_values = np.unique(X_train[:, feat_idx])\n",
    "    frequencies = [(float(len(np.where(X_train[:, feat_idx]==value)[0]))/X_train.shape[0]) \\\n",
    "                   for value in feature_values]\n",
    "\n",
    "    # afficher le diagramme en barres pour la variable feat_idx\n",
    "    b = ax.bar(range(len(feature_values)), frequencies, width=0.5, \n",
    "               tick_label=list([int(n) for n in feature_values]))\n",
    "    \n",
    "    # utiliser le nom de la variable comme titre pour chaque histogramme\n",
    "    ax.set_title(features[feat_idx])\n",
    "fig.tight_layout(pad=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ En vous inspirant du code ci-dessus et de la PC3, affichez les histogrammes des variables continues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Réponse :\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "\n",
    "# Histogrammes pour les variables continues\n",
    "for (plot_idx, feat_idx) in enumerate(continuous_features_idx):\n",
    "    # créer une sous-figure (subplot) à la position (plot_idx+1) d'une grille 2x2\n",
    "    ax = fig.add_subplot(2, 2, (plot_idx+1))\n",
    "    \n",
    "    # afficher l'histogramme de la variable feat_idx\n",
    "    h = ax.hist(X_train[:, feat_idx], bins=30, edgecolor='none')\n",
    "    \n",
    "    # utiliser le nom de la variable comme titre pour chaque diagramme\n",
    "    ax.set_title(features[feat_idx])\n",
    "    \n",
    "# espacement entre les subplots\n",
    "fig.tight_layout(pad=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Quelles sont les fourchettes de valeur prises par les différentes variables ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ Il s'agit ici d'observer que certaines valeurs ont des ordres de grandeur différents d'autres (poids vs accélération, année ou pays)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Tracer l'histogramme des étiquettes du jeu d'entrainement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_train, bins=30, edgecolor='none')\n",
    "plt.title('mpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Un premier modèle\n",
    "\n",
    "Nous allons maintenant construire une _baseline_, c'est-à-dire un premier modèle qui nous servira de point de comparaison. Ici, il s'agit d'utiliser `scikit-learn` pour entraîner une régression linéaire sur les données sans les prétraiter.\n",
    "\n",
    "Les modèles linéaires de `scikit-learn` sont implémentés dans le module [`sklearn.linear_model`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model). __N'hésitez pas à vous référer fréquemment à la documentation de scikit-learn, qui est très complète.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entraînement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciation d'un objet LinearRegression\n",
    "predictor = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrainement de cet objet sur les données d'entraînement\n",
    "predictor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prédiction sur les données de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predictor.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance\n",
    "\n",
    "Il s'agit maintenant d'évaluer ces prédictions. Pour cela, nous allons utiliser les fonctionalités du module [`metrics`](https://scikit-learn.org/stable/api/sklearn.metrics.html) de `scikit-learn`.\n",
    "\n",
    "Comme il s'agit d'un problème de régression, nous allons utiliser la __RMSE__ (_Root Mean Squared Error_) comme mesure de la performance du modèle : il s'agit de la racine carrée de la moyenne des carrés des erreurs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Pourquoi prendre la racine carrée et pas simplement la MSE ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ Pour des questions d'homogénéité : la RMSE s'exprime dans la même unité que l'étiquette."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"RMSE: {metrics.root_mean_squared_error(y_test, y_pred):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Que pensez-vous de cette erreur ? Est-elle faible? Grande ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ Vu la fourchette de valeurs des étiquettes (environ entre 10 et 45), une erreur de 3.29 n'est pas si mal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons aussi utiliser une visualisation, et représenter chaque individu du jeu de test par son étiquette prédite vs. sa vraie étiquette."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test, y_pred)\n",
    "\n",
    "plt.xlabel(\"Consommation réelle (mpg)\")\n",
    "plt.ylabel(\"Consommation prédite (mpg)\")\n",
    "plt.title(\"Régression linéaire\")\n",
    "\n",
    "# Mêmes valeurs sur les deux axes\n",
    "axis_min = np.min([np.min(y_test), np.min(y_pred)])-1\n",
    "axis_max = np.max([np.max(y_test), np.max(y_pred)])+1\n",
    "plt.xlim(axis_min, axis_max)\n",
    "plt.ylim(axis_min, axis_max)\n",
    "  \n",
    "# Diagonale y=x\n",
    "plt.plot([axis_min, axis_max], [axis_min, axis_max], 'k-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coefficients de régression\n",
    "\n",
    "Pour comprendre notre modèle, nous pouvons regarder les coefficients affectés à chaque variable dans le modèle linéaire appris."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher, pour chaque variable, son poids dans le modèle (en valeur absolue)\n",
    "num_features = X_train.shape[1]\n",
    "feature_names = df.drop(columns=['mpg', 'car name']).columns\n",
    "plt.scatter(range(num_features), np.abs(predictor.coef_))\n",
    "\n",
    "plt.xlabel('Variable')\n",
    "tmp = plt.xticks(range(num_features), feature_names, rotation=90)\n",
    "tmp = plt.ylabel('Coefficient')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Quelle variable a le plus fort coefficient (en valeur absolue) ? Pensez-vous que cela signifie que cette variable joue un rôle très important dans la prédiction ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ C'est l'origine géographique de la voiture. Il ne faut pas oublier que les variables prennent des valeurs très différentes, `origin` a des valeurs entre 1 et 3 et `weight` entre 2000 et 5000... L'interprétation est difficile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corrélation\n",
    "\n",
    "La corrélation des variables peut brouiller notre interprétation des poids attribués à chaque variable par notre modèle. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question :** Représentez la corrélation entre les variables de notre jeu de données (s'inspirer de la PC3. Attention, la corrélation n'a de sens qu'entre des variables quantitatives). Qu'en conclure quant à l'interprétabilité des coefficients affectés aux variables ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "corr_mat = df.drop(columns=['mpg', 'car name', 'origin']).corr() # enlever origin dont les valeurs numériques ne sont qu'un encodage de régions du monde.\n",
    "plt.figure(figsize=(5, 4))\n",
    "# Affichage heatmap\n",
    "sns.heatmap(corr_mat, \n",
    "            vmin=-1, # borne inf des valeurs à afficher\n",
    "            vmax=1, # borne sup des valeurs à afficher\n",
    "            center= 0, # valeur médiane des valeurs à afficher,\n",
    "            cmap='PuOr', # colormap divergente de violet (PUrple) vers orange (ORange)\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les quatres variables cylinders, displacement, horspower et weight sont fortement positivement corrélées. Plusieurs solutions pour les valeurs de ces coefficients sont possibles, en \"compensant\" un changement dans un coefficient par d'autres changements dans les coefficients des autres variables corrélées. Il est difficile d'interpréter les valeurs des coefficients dans ces conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Encodage des variables qualitatives\n",
    "La variable `origin` est une variable qualitative : l'encodage 1-2-3 est tout à fait arbitraire. Il suppose en particulier, si on réfléchit en termes de distances, que l'Asie est deux fois plus loin de l'Amérique du Nord que de l'Europe, ce qui n'a aucun sens.\n",
    "\n",
    "Un encodage plus raisonnable pour ce genre de cas est ce qu'on appelle l'encodage _one-hot_, ou encore _dummy encoding_ : on représente la variable par autant de variables binaires qu'il y a de valeurs possibles (3 dans le cas de la variable `origin` : la première correspond à Amérique du Nord, la deuxième à Europe, la troisième à Asie), et on met à `1` la seule de ces variables binaires correspondant à la valeur que l'on encode.\n",
    "\n",
    "Ainsi l'unique variable `origin` devient 3 variables binaires:\n",
    "```    \n",
    "   Amérique du Nord --> 1, 0, 0\n",
    "   Europe --> 0, 1, 0\n",
    "   Asie --> 0, 0, 1\n",
    "```  \n",
    "Cette représentation a l'inconvénient d'augmenter le nombre de variables, mais les distances euclidiennes sont maintenant plus raisonnables (elles valent 1 si les valeurs sont différentes et 0 si elles sont identiques)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette fonctionalité existe dans `pandas` comme dans `scikit-learn`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un nouveau data frame où la colomne 'origin' est remplacée par son encodage 'one-hot'\n",
    "df_dummies = pd.get_dummies(df, columns=['origin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraire de nouveau les données\n",
    "X_dummies = np.array(df_dummies.drop(columns=['mpg', 'car name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dummies_train, X_dummies_test, y_d_train, y_d_test = model_selection.train_test_split(X_dummies, y, \n",
    "                                                                                        test_size=0.20, \n",
    "                                                                                        random_state=27)\n",
    "                                                                                                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez vérifier ici que l'utilisation de la même graine pour `random_state` génère la même répartition des données que précédemment :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.abs(y_d_train-y_train)) + np.sum(np.abs(y_d_test-y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impact sur le modèle\n",
    "\n",
    "Nous allons maintenant apprendre une régression linéaire sur les données où la variable `origin` a été remplacée par son encodage one-hot. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Créer une instance `predictor_dummy` de la classe `LinearRegression` entraînée sur les données contenant la version _one-hot_ de la variable `origin`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un nouvel objet LinearRegression \n",
    "predictor_dummy = linear_model.LinearRegression()\n",
    "\n",
    "# Entraîner predictor_dummy sur les nouvelles données\n",
    "predictor_dummy.fit(X_dummies_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Créer un array `y_pred_dummy` qui contient les prédictions de la nouvelle régression linéaire sur les données de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dummy = predictor_dummy.predict(X_dummies_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Quelle est la RMSE, sur le jeu de test, de ce nouveau modèle ? La comparer à la RMSE précédente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"RMSE (encodage one-hot): {metrics.root_mean_squared_error(y_test, y_pred_dummy):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ La RMSE est un tout petit peu plus faible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparaison aux prédictions de la baseline\n",
    "\n",
    "Les performances sont-elles vraiment différentes ? Nous pouvons comparer les prédictions directement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test, y_pred, label='Baseline')\n",
    "plt.scatter(y_test, y_pred_dummy, label='Avec one-hot')\n",
    "\n",
    "plt.xlabel(\"Consommation réelle (mpg)\")\n",
    "plt.ylabel(\"Consommation prédite (mpg)\")\n",
    "plt.title(\"Régression linéaire\")\n",
    "\n",
    "# Mêmes valeurs sur les deux axes\n",
    "axis_min = np.min([np.min(y_test), np.min(y_pred), np.min(y_pred_dummy)])-1\n",
    "axis_max = np.max([np.max(y_test), np.max(y_pred), np.max(y_pred_dummy)])+1\n",
    "plt.xlim(axis_min, axis_max)\n",
    "plt.ylim(axis_min, axis_max)\n",
    "  \n",
    "# Diagonale y=x\n",
    "plt.plot([axis_min, axis_max], [axis_min, axis_max], 'k-')\n",
    "\n",
    "plt.legend(loc=(0.02, 0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_pred, y_pred_dummy)\n",
    "\n",
    "plt.xlabel(\"Consommation prédite (mpg) (baseline)\")\n",
    "plt.ylabel(\"Consommation prédite (mpg) (avec one-hot)\")\n",
    "plt.title(\"Régression linéaire\")\n",
    "\n",
    "# Mêmes valeurs sur les deux axes\n",
    "axis_min = np.min([np.min(y_pred), np.min(y_pred_dummy)])-1\n",
    "axis_max = np.max([np.max(y_pred), np.max(y_pred_dummy)])+1\n",
    "plt.xlim(axis_min, axis_max)\n",
    "plt.ylim(axis_min, axis_max)\n",
    "  \n",
    "# Diagonale y=x\n",
    "plt.plot([axis_min, axis_max], [axis_min, axis_max], 'k-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, pval = st.pearsonr(y_pred, y_pred_dummy)\n",
    "print(f\"Corrélation entre les prédictions : : {r:.2f} (p={pval:.2e})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coefficients de régression\n",
    "\n",
    "Comparons maintenant les deux modèles visuellement :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Afficher, sur le même graphique, les poids (en valeur absolue) de chaque variable dans chacun des deux modèles `predictor` et `predictor_dummy`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Même code que précédemment pour les poids de predictor\n",
    "num_features = X_train.shape[1]\n",
    "plt.scatter(range(num_features), np.abs(predictor.coef_), label='Original')\n",
    "\n",
    "# Code adapté pour les poids de predictor_dummy\n",
    "num_features2 = X_dummies_train.shape[1]\n",
    "plt.scatter(range(num_features2), np.abs(predictor_dummy.coef_), label='Avec one-hot', marker='v')\n",
    "feature_names2 = df_dummies.drop(columns=['mpg', 'car name']).columns\n",
    "\n",
    "plt.xlabel('Variable')\n",
    "tmp = plt.xticks(range(num_features2), feature_names2, rotation=90)\n",
    "tmp = plt.ylabel('Coefficient')\n",
    "\n",
    "plt.legend(loc=(0.02, 0.75))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Ce modèle est-il vraiment différent du précédent ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ La contribution de chaque origine au modèle précédent est :\n",
    "```\n",
    "    Amérique du Nord : predictor.coef_[-1] ~ 1.62\n",
    "    Europe : 1.62 x 2 ~ 3.24\n",
    "    Asie : 1.62 x 3 ~ 4.86\n",
    "```\n",
    "Pour le nouveau modèle :\n",
    "```\n",
    "    Amérique du Nord : predictor_dummy.coef_[-3] ~ -1.95\n",
    "    Europe : predictor_dummy.coef_[-2] ~ 0.68\n",
    "    Asie : predictor_dummy.coef_[-1] ~ 1.28\n",
    "```\n",
    "Les autres coefficients ne changent pas.\n",
    "\n",
    "Les modèles sont très légèrements différents mais cette différence a peu d'impact. __Ça ne veut pas dire que cette transformation n'a jamais d'intérêt en général...__    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Ramener les variables à des échelles comparables\n",
    "\n",
    "Le fait que les variables soient sur des échelles différentes rend l'interprétation des coefficients de la régression linéaire délicate. \n",
    "\n",
    "### 5.1 Centrer et réduire les variables\n",
    "\n",
    "Centrer et réduire les variables (comme nous l'avons vu dans la PC3) permet de remédier à ce problème."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformation des variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_scaler = preprocessing.StandardScaler()\n",
    "standard_scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = standard_scaler.transform(X_train)\n",
    "X_test_scaled = standard_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation des nouvelles variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ En s'inspirant du code de la section 2, créer une grille de figures de taille 4x2, et affichez côte à côte, pour chacune des variables continues, en bleu son histogramme dans `X_train` et en orange son histogramme dans `X_train_scaled`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 10))\n",
    "\n",
    "# Histogrammes pour les variables continues\n",
    "for (plot_idx, feat_idx) in enumerate(continuous_features_idx):\n",
    "    # créer une sous-figure (subplot) à la position (plot_idx+1) d'une grille 4x2\n",
    "    ax = fig.add_subplot(4, 2, (2*plot_idx+1))\n",
    "    \n",
    "    # afficher l'histogramme de la variable feat_idx dans X_train\n",
    "    h = ax.hist(X_train[:, feat_idx], bins=30, edgecolor='none')\n",
    "    \n",
    "    # utiliser le nom de la variable comme titre de l'histogramme\n",
    "    ax.set_title(\"%s (original)\" % features[feat_idx])    \n",
    "    \n",
    "    # créer une sous-figure (subplot) à la position (plot_idx+2) d'une grille 4x2\n",
    "    ax = fig.add_subplot(4, 2, (2*plot_idx+2))\n",
    "    \n",
    "    # afficher l'histogramme de la variable feat_idx dans X_train_scaled\n",
    "    h = ax.hist(X_train_scaled[:, feat_idx], bins=30, edgecolor='none', color='orange')\n",
    "    \n",
    "    # utiliser le nom de la variable comme titre de l'histogramme\n",
    "    ax.set_title(\"%s (centrée-réduite)\" % features[feat_idx])\n",
    "    \n",
    "# espacement entre les subplots\n",
    "fig.tight_layout(pad=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ En s'inspirant du code de la section 2, créer une grille de figures de taille 3x2, et affichez côte à côte, pour chacune des variables discrètes, en bleu le diagramme en barre des fréquences de ses valeurs prises dans `X_train`, et en orange le diagramme en barre des fréquences de ses valeurs prises dans `X_train_scaled`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "\n",
    "# Variables dans X_train\n",
    "for (plot_idx, feat_idx) in enumerate(discrete_features_idx):\n",
    "    # créer une sous-figure (subplot) à la position (2*plot_idx+1) d'une grille 3x2\n",
    "    ax = fig.add_subplot(3, 2, (2*plot_idx+1))\n",
    "    \n",
    "    # créeer le diagramme en barre comme précédemment\n",
    "    feature_values = np.unique(X_train[:, feat_idx])\n",
    "    frequencies = [(float(len(np.where(X_train[:, feat_idx]==value)[0]))/X_train.shape[0]) \\\n",
    "                   for value in feature_values]\n",
    "    tick_labels = feature_values.astype(int)\n",
    "    b = ax.bar(range(len(feature_values)), frequencies, width=0.5, tick_label=tick_labels)    \n",
    "    \n",
    "    # utiliser le nom de la variable comme titre de l'histogramme\n",
    "    ax.set_title(\"%s (originale)\" % features[feat_idx])\n",
    "\n",
    "# Variables dans X_train_scaled\n",
    "for (plot_idx, feat_idx) in enumerate(discrete_features_idx):\n",
    "    # créer une sous-figure (subplot) à la position (2*plot_idx+2) d'une grille 3x2\n",
    "    ax = fig.add_subplot(3, 2, (2*plot_idx+2))\n",
    "    \n",
    "    # créeer le diagramme en barre comme précédemment\n",
    "    feature_values = np.unique(X_train_scaled[:, feat_idx])\n",
    "    frequencies = [(float(len(np.where(X_train_scaled[:, feat_idx]==value)[0]))/X_train_scaled.shape[0]) \\\n",
    "                   for value in feature_values]\n",
    "    tick_labels = [\"%.1f\" % v for v in feature_values]\n",
    "    b = ax.bar(range(len(feature_values)), frequencies, width=0.5, \n",
    "               tick_label=tick_labels, color='orange')  \n",
    "    \n",
    "    # utiliser le nom de la variable comme titre de l'histogramme\n",
    "    ax.set_title(\"%s (centrée-réduite)\" % features[feat_idx])\n",
    "\n",
    "# espacement entre les subplots\n",
    "fig.tight_layout(pad=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Impact sur le modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Entrainez un modèle `predictor_scaled` sur les données centrées-réduites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un nouvel objet LinearRegression \n",
    "predictor_scaled = linear_model.LinearRegression()\n",
    "\n",
    "# Entraîner predictor_scaled sur les nouvelles données\n",
    "predictor_scaled.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Créer un array `y_pred_scaled` qui contient les prédictions de `predictor_scaled` sur le jeu de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_scaled = predictor_scaled.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Quelle est la RMSE, sur le jeu de test, de ce nouveau modèle ? La comparer à la RMSE précédente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"RMSE (scaled): {metrics.root_mean_squared_error(y_test, y_pred_scaled):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ La RMSE n'a pas changé."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Comparer les coefficients de régression des deux modèles. Quelles sont les variables les plus pertinentes pour prédire la consommation d'un véhicule ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comme précédemment pour les coefficients de régression dans predictor\n",
    "num_features = X_train.shape[1]\n",
    "plt.scatter(range(num_features), np.abs(predictor.coef_), label='Originales')\n",
    "\n",
    "# Même code modifié pour afficher les coefficients de régression dans predictor_scaled\n",
    "plt.scatter(range(num_features), np.abs(predictor_scaled.coef_), label='Centrées-réduites', marker='v')\n",
    "\n",
    "plt.xlabel('Variable')\n",
    "tmp = plt.xticks(range(num_features), feature_names, rotation=90)\n",
    "tmp = plt.ylabel('Coefficient')\n",
    "plt.legend(loc=(0.02, 0.75))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ On peut maintenant interpréter les coefficients de régression : les variables les plus importantes sont le poids, l'année et la cylindrée. On voit que l'origine est beaucoup moins pertinente qu'on aurait pu le croire."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Remarque :__ Réfléchir au fait que les prédictions sont exactement les mêmes mais pas les coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Réduction min-max\n",
    "La __réduction min-max__ est une autre façon de ramener les variables sur une même échelle, en les ramenant entre 0 et 1 par $x_j \\leftarrow (x_j - \\min(x_j))/(\\max(x_j)-\\min(x_j))$.\n",
    "\n",
    "Dans `scikit-learn`, elle est implémentée de manière très simimlaire à `StandardScaler` dans [`preprocessing.MinMaxScaler()`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html). \n",
    "\n",
    "__Question :__ Reproduisez l'analyse de la section 5.1 avec cette nouvelle transformation des données. Les résultats sont-ils différents de la section 5.1 ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformation des variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax_scaler = preprocessing.MinMaxScaler()\n",
    "minmax_scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_minmax = minmax_scaler.transform(X_train)\n",
    "X_test_minmax = minmax_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation des variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 10))\n",
    "\n",
    "# Histogrammes pour les variables continues\n",
    "for (plot_idx, feat_idx) in enumerate(continuous_features_idx):\n",
    "    # Comme précédemment\n",
    "    ax = fig.add_subplot(4, 2, (2*plot_idx+1))\n",
    "    h = ax.hist(X_train[:, feat_idx], bins=30, edgecolor='none')\n",
    "    ax.set_title(\"%s (original)\" % features[feat_idx])    \n",
    "    \n",
    "    ax = fig.add_subplot(4, 2, (2*plot_idx+2))\n",
    "    h = ax.hist(X_train_scaled[:, feat_idx], bins=30, edgecolor='none', color='orange', \n",
    "                alpha=0.75 # on ajoute un peu de transparence\n",
    "               )\n",
    "    ax.set_title(\"%s (centrée-réduite)\" % features[feat_idx])\n",
    "\n",
    "    # Superposer l'histogramme pour la nouvelle transformation sur la précédente\n",
    "    h = ax.hist(X_train_minmax[:, feat_idx], bins=30, edgecolor='none', color='purple', \n",
    "                alpha=0.75 # on ajoute un peu de transparence\n",
    "               )\n",
    "    ax.set_title(\"%s (minmax)\" % features[feat_idx])\n",
    "    \n",
    "# espacement entre les subplots\n",
    "fig.tight_layout(pad=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Impact sur le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instancier un nouvel objet LinearRegression \n",
    "predictor_minmax = linear_model.LinearRegression()\n",
    "\n",
    "# Entraîner predictor_minmax sur les nouvelles données\n",
    "predictor_minmax.fit(X_train_minmax, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_minmax = predictor_minmax.predict(X_test_minmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"RMSE (scaled): {metrics.root_mean_squared_error(y_test, y_pred_minmax):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comme précédemment pour les coefficients de régression dans predictor\n",
    "num_features = X_train.shape[1]\n",
    "plt.scatter(range(num_features), np.abs(predictor.coef_), label='Originales')\n",
    "\n",
    "# Comme précédemment pour les coefficients de régression dans predictor_scaled\n",
    "plt.scatter(range(num_features), np.abs(predictor_scaled.coef_), label='Centrées-réduites', marker='v')\n",
    "\n",
    "# Même code modifié pour afficher les coefficients de régression dans predictor_minmax\n",
    "plt.scatter(range(num_features), np.abs(predictor_minmax.coef_), label='Minmax', marker='^')\n",
    "\n",
    "plt.xlabel('Variable')\n",
    "tmp = plt.xticks(range(num_features), feature_names, rotation=90)\n",
    "tmp = plt.ylabel('Coefficient')\n",
    "plt.legend(loc=(0.02, 0.65))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Interprétation :__ Toujours le même modèle prédictif, les poids changent car les fourchettes ne sont pas les mêmes mais l'importante respective des variables est intouchée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Normalisation des variables\n",
    "\n",
    "Vous l'aurez remarqué en regardant les histogrammes : nos variables continues ne semblent pas suivre une distribution normale. \n",
    "\n",
    "Dans le cas de la régression linéaire, nous n'avons fait aucune hypothèse sur la normalité des variables : nous avons supposés que les résidus sont normalement distribués. Cependant, transformer les variables pour les rapprocher de gaussiennes peut permettre d'améliorer les modèles, en particulier en contrôlant l'[asymétrie](https://fr.wikipedia.org/wiki/Asym%C3%A9trie_(statistiques)) des valeurs. \n",
    "\n",
    "`scikit-learn` permet d'appliquer deux types de transformations normales des variables : \n",
    "* la __transformation Box-Cox__, qui ne s'applique qu'à des variables non nulles positives. C'est cette première que nous allons illustrer ici.\n",
    "* la __transformation de Yeo-Johnson__.\n",
    "  \n",
    "Ces deux méthodes sont disponibles dans la classe [`sklearn.preprocessing.PowerTransformer`](https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-transformer) et vous pouvez en lire plus à leur sujet dans [la doc](https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-transformer).\n",
    "\n",
    "__Remarque pour aller plus loin:__ Un histogramme n'est pas un très bon moyen de vérifier qu'une distribution empirique correspond à une distribution théorique. On leur préfère plutôt un [diagramme quantile-quantile (QQ-plot)](https://fr.wikipedia.org/wiki/Diagramme_quantile-quantile), que l'on peut construire avec [la méthode `probplot` de `scipy.stats`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.probplot.html) ou... un test statistique (pour la normalité, on utilise par exemple le [test de Shapiro-Wilk](https://fr.wikipedia.org/wiki/Test_de_Shapiro-Wilk) (pour se comparer à une loi normale) ou le [test de Kolmogorov-Smirnov](https://fr.wikipedia.org/wiki/Test_de_Kolmogorov-Smirnov) (pour se comparer à une loi dont on a la fonction de répartition). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation Box-Cox des variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxcox_scaler = preprocessing.PowerTransformer(method='box-cox')\n",
    "boxcox_scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_boxcox = boxcox_scaler.transform(X_train)\n",
    "X_test_boxcox = boxcox_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation des variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Afficher, pour chaque variable continue, son histogramme dans `X_train_scaled`, et lui superposer (dans une autre couleur contrastante) son histogramme dans `X_train_boxcox`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Même code que précédemment pour afficher les histogrammes des variables de X_train_scaled sur une grille 2x2\n",
    "for (plot_idx, feat_idx) in enumerate(continuous_features_idx): \n",
    "    ax = fig.add_subplot(2, 2, (plot_idx+1))\n",
    "    h = ax.hist(X_train_scaled[:, feat_idx], bins=30, edgecolor='none', color='orange', alpha=0.75, \n",
    "               label='centrée-réduite')\n",
    "    \n",
    "    # superposer l'histogramme pour la nouvelle transformation \n",
    "    h = ax.hist(X_train_boxcox[:, feat_idx], bins=30, edgecolor='none', color='purple', alpha=0.75,\n",
    "               label='Box-Cox')\n",
    "    \n",
    "    ax.set_title(\"%s\" % features[feat_idx])   \n",
    "    ax.legend(loc=(0.7, 0.7))\n",
    "    \n",
    "# espacement entre les subplots\n",
    "fig.tight_layout(pad=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impact sur le modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Quel est l'impact de cette transformation sur le modèle ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Impact sur la performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instancier un nouvel objet LinearRegression \n",
    "predictor_boxcox = linear_model.LinearRegression()\n",
    "\n",
    "# Entraîner predictor_boxcox sur les nouvelles données\n",
    "predictor_boxcox.fit(X_train_boxcox, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_boxcox = predictor_boxcox.predict(X_test_boxcox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"RMSE (scaled): {metrics.root_mean_squared_error(y_test, y_pred_boxcox):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La performance s'est améliorée !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Impact sur les coefficients de régression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher, pour chaque variable, son poids dans le modèle (en valeur absolue)\n",
    "num_features = X_train.shape[1]\n",
    "plt.scatter(range(num_features), np.abs(predictor.coef_), label='Originales')\n",
    "plt.scatter(range(num_features), np.abs(predictor_scaled.coef_), label='Centrées-réduites', marker='v')\n",
    "plt.scatter(range(num_features), np.abs(predictor_boxcox.coef_), label='Box-Cox', marker='^')\n",
    "\n",
    "plt.xlabel('Variable')\n",
    "tmp = plt.xticks(range(num_features), feature_names, rotation=90)\n",
    "tmp = plt.ylabel('Coefficient')\n",
    "plt.legend(loc=(0.02, 0.65))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En utilisant la transformation Box-Cox, on donne maintenant plus d'importance à l'accélération et aux CV, et moins au poids du véhicule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparaison aux prédictions de la baseline\n",
    "\n",
    "Nous pouvons aussi comparer les prédictions faites par ce nouveau modèles à celles de la _baseline_ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test, y_pred, label='Baseline')\n",
    "plt.scatter(y_test, y_pred_boxcox, label='Box-Cox')\n",
    "\n",
    "plt.xlabel(\"Consommation réelle (mpg)\")\n",
    "plt.ylabel(\"Consommation prédite (mpg)\")\n",
    "plt.title(\"Régression linéaire\")\n",
    "\n",
    "# Mêmes valeurs sur les deux axes\n",
    "axis_min = np.min([np.min(y_test), np.min(y_pred), np.min(y_pred_boxcox)])-1\n",
    "axis_max = np.max([np.max(y_test), np.max(y_pred), np.max(y_pred_boxcox)])+1\n",
    "plt.xlim(axis_min, axis_max)\n",
    "plt.ylim(axis_min, axis_max)\n",
    "  \n",
    "# Diagonale y=x\n",
    "plt.plot([axis_min, axis_max], [axis_min, axis_max], 'k-')\n",
    "\n",
    "plt.legend(loc=(0.02, 0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_pred, y_pred_boxcox)\n",
    "\n",
    "plt.xlabel(\"Consommation prédite (mpg) (baseline)\")\n",
    "plt.ylabel(\"Consommation prédite (mpg) (Box-Cox)\")\n",
    "plt.title(\"Régression linéaire\")\n",
    "\n",
    "# Mêmes valeurs sur les deux axes\n",
    "axis_min = np.min([np.min(y_pred), np.min(y_pred_boxcox)])-1\n",
    "axis_max = np.max([np.max(y_pred), np.max(y_pred_boxcox)])+1\n",
    "plt.xlim(axis_min, axis_max)\n",
    "plt.ylim(axis_min, axis_max)\n",
    "  \n",
    "# Diagonale y=x\n",
    "plt.plot([axis_min, axis_max], [axis_min, axis_max], 'k-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, pval = st.pearsonr(y_pred, y_pred_boxcox)\n",
    "print(f\"Corrélation entre les prédictions : {r:.2f} (p={pval:.2e})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Remarque :__ Les prédictions sont très corrélées avec celles obtenues avec la deuxième transformation : le modèle est différent et sa performance semble meilleure, mais cette différence n'est peut-être pas significative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Pour aller plus loin\n",
    "\n",
    "Le pré-traitement des données est une partie importante du travail de _data scientist_. Voici quelques ressources et remarques pour aller plus loin :\n",
    "* La transformation en vecteurs de données non-structurées (telles que texte ou images) est possible à travers des techniques telles que :\n",
    "  * pour le texte : les approches bag-of-word ou tf-idf (voir [la doc scikit-learn](https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction) ou [le cours OpenClassrooms Analysez vos données textuelles](https://openclassrooms.com/fr/courses/4470541-analysez-vos-donnees-textuelles)) ;\n",
    "  * pour les images : les approches telles que SIFT (voir [le cours OpenClassrooms Classez et segmentez des données visuelles](https://openclassrooms.com/fr/courses/4470531-classez-et-segmentez-des-donnees-visuelles)).\n",
    "  \n",
    "* Les méthodes à noyaux et l'apprentissage profond, que nous aborderons brièvement à la fin de ce cours, permettent d'aborder autrement la représentation de données non-structurées.\n",
    "\n",
    "* https://github.com/mirekphd/awesome-feature-engineering\n",
    "* https://machinelearningmastery.com/discover-feature-engineering-how-to-engineer-features-and-how-to-get-good-at-it/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
