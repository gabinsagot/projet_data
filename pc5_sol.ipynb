{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PC5 - Sélection de modèle et régularisation - 27 juin 2024 - Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce notebook, nous allons utiliser des données simulées pour mieux comprendre les __régularisations L1 et L2__. Ce sera aussi l'occasion de mettre en place une __recherche sur grille__ pour sélectionner le coefficient de régularisation par validation croisée. \n",
    "\n",
    "Dans la dernière partie, vous pourrez mettre en œuvre ces algorithmes sur un jeu de données réelles.\n",
    "\n",
    "Ce notebook sera aussi l'occasion d'aborder un premier algorithme d'apprentissage supervisé _non-linéaire_, la __régression polynomiale__.\n",
    "\n",
    "Ce notebook a été initialement proposé par [Arthur Imbert](https://github.com/Henley13)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import de numpy et matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('font', **{'size': 12}) # règle la taille de police globalement pour les plots (en pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On fixe ici la graine pour le générateur de nombres aléatoires, pour faciliter la reproducibilité\n",
    "np.random.seed(19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Régularisation L2 (ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Simulation de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commençons par simuler un jeu de données de 30 échantillons avec une seule variable prédictive (p=1) et dans lequel l'étiquette est une fonction non-linéaire (sinusoïdale) de cette variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_samples = 30\n",
    "\n",
    "# vrai modèle (Y = true_f(X))\n",
    "def true_f(x):\n",
    "    return np.cos(1.5 * np.pi * x) * 5\n",
    "\n",
    "# tirer nb_samples valeurs de x entre 0 et 1\n",
    "X = np.random.rand(nb_samples, 1)\n",
    "y = true_f(X)\n",
    "\n",
    "# ajouter du bruit\n",
    "y += np.random.randn(nb_samples, 1) * 0.3\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons maintenant visualiser ce que nous venons de simuler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "# Pour afficher le vrai modèle :\n",
    "# créer 100 points de vraies paires (x, y) \n",
    "# créer un array de dimension (1, 100) contenant 100 valeurs régulièrement espacées entre 0 et 1  \n",
    "X_grid = np.linspace(0, 1, 100).reshape(-1, 1)\n",
    "# calculer leurs étiquettes\n",
    "y_true = true_f(X_grid)\n",
    "plt.plot(X_grid, y_true, label=\"vérité\", color=\"black\", linewidth=1, linestyle='dashed')\n",
    "\n",
    "# Afficher les données simulées\n",
    "plt.scatter(X, y, label=\"observations simulées\", color=\"tab:blue\", marker=\"+\", s=50)\n",
    "\n",
    "# Mise en forme\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"$y$\")\n",
    "plt.xlim((0, 1))\n",
    "plt.ylim((-7, 7))\n",
    "\n",
    "plt.title(\"Vrai modèle et données simulées\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons maintenant séparer nos données en un jeu d'entraînement et un jeu de test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ En s'inspirant de la PC4, séparer (`X`, `y`) en un jeu d'entraînement (`X_train`, `y_train`) et un jeu de test (`X_test`, `y_test`). Le jeu de test contiendra 30% des données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, \n",
    "                                                                    test_size=0.3, \n",
    "                                                                    random_state=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Reproduire le graphique précédent, mais distinguer jeu d'entraînement (+) et jeu de test (x) parmi les observations simulées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "# Afficher le vrai modèle\n",
    "plt.plot(X_grid, y_true, label=\"vérité\", color=\"black\", linewidth=1, linestyle='dashed')\n",
    "\n",
    "# Afficher les données simulées (entraînement)\n",
    "plt.scatter(X_train, y_train, label=\"jeu d'entraînement\", c=\"tab:blue\", marker=\"+\", s=50)\n",
    "# Afficher les données simulées (test)\n",
    "plt.scatter(X_test, y_test, label=\"jeu de test\", c=\"tab:blue\", marker=\"x\", s=50)\n",
    "\n",
    "# Mise en forme\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"$y$\")\n",
    "plt.xlim((0, 1))\n",
    "plt.ylim((-7, 7))\n",
    "\n",
    "plt.title(\"Vrai modèle et données simulées\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Régression linéaire classique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entraînement du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ En s'inspirant de la PC4, entraîner une régression linéaire sur `(X_train, y_train)`. Appeler le modèle `linreg`.\n",
    "\n",
    "Remarquez que les variables ayant été générées centrées-réduites, il n'est pas nécessaire de leur appliquer cette transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instancier un objet LinearRegression\n",
    "linreg = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrainer cet objet sur les données d'entraînement\n",
    "linreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons écrire explicitement le modèle appris en accédant à ses coefficients :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"L'équation du modèle appris est : y = {linreg.coef_[0][0]:.2f} x + {linreg.intercept_[0]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Calculer le [coefficient de détermination](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html) de `linreg` sur le jeu d'entraînement et sur le jeu de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_r2_train = metrics.r2_score(y_train, linreg.predict(X_train))\n",
    "print(f\"R2 de la régression linéaire sur le jeu d'entraînement : {linreg_r2_train:.2f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_r2_test = metrics.r2_score(y_test, linreg.predict(X_test))\n",
    "print(f\"R2 de la régression linéaire sur le jeu de test : {linreg_r2_test:.2f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Pourquoi comparer ces deux performances ? Qu'en conclure ici ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ Si la performance est moins bonne sur le jeu de test, cela indique une situation de sur-apprentissage. Si la performance est mauvaise sur les deux jeux (en particulier celui d'entraînement), cela indique un sous-apprentissage.\n",
    "\n",
    "Ici, le modèle sous-apprend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Remarque :__ La différence entre les performances va dépendre d'où sont situées les observations de chacun des deux jeux.\n",
    "\n",
    "Par exemple, si tous les points du jeu d'entraînement sont situés entre $x=0,2$ et $x=0,6$, le modèle est bien approché par une droite et la performance sur le jeu d'entraînement sera bonne. Cette droite est une mauvaise approximation de ce qui se passe à l'extérieur de cet intervalle, si le jeu de test contient des points qui s'y trouvent, la performance sera fortement dégradée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Ajouter au graphique précédent le modèle appris."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "# Afficher le vrai modèle\n",
    "plt.plot(X_grid, y_true, label=\"vérité\", color=\"black\", linewidth=1, linestyle='dashed')\n",
    "\n",
    "# Afficher les données simulées (entraînement)\n",
    "plt.scatter(X_train, y_train, label=\"jeu d'entraînement\", color=\"tab:blue\", marker=\"+\", s=50)\n",
    "# Afficher les données simulées (test)\n",
    "plt.scatter(X_test, y_test, label=\"jeu de test\", color=\"tab:green\", marker=\"x\", s=50)\n",
    "\n",
    "# Calculer les prédictions pour les points de X_grid\n",
    "y_linreg = linreg.predict(X_grid)\n",
    "# Afficher le modèle corredpondant\n",
    "plt.plot(X_grid, y_linreg, label=\"régression linéaire\",\n",
    "         color=\"tab:orange\", linewidth=2)\n",
    "# (Remarque : on sait ici qu'il s'agit d'une droite donc on pourrait ne calculer que 2 points,\n",
    "# mais le code proposé ici est générique)\n",
    "\n",
    "# Mise en forme\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"$y$\")\n",
    "plt.xlim((0, 1))\n",
    "plt.ylim((-7, 7))\n",
    "\n",
    "plt.title(\"Régression linéaire\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Régression polynomiale "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons jusqu'à présent travaillé avec une seule variable.\n",
    "\n",
    "Pour essayer d'améliorer notre modèle, nous pouvons _créer de nouvelles variables_ à partir de celle-ci (par exemple $x^2+x^3$, $\\log(x)$, $e^{x-17}$) et apprendre un modèle linéaire sur ces nouvelles variables. Plutôt que de procéder à tatons comme dans les exemples entre parenthèse, on peut se limiter aux _puissances_ de notre variable $x$.\n",
    "\n",
    "Ainsi, nous allons remplacer l'unique variable $x$ par $d$ variables $x, x^2, x^3, \\dots, x^d$. Apprendre une fonction linéaire de ces $d$ variables est équivalent à apprendre un polynôme de degré $d$ de $x$. C'est une première approche pour apprendre un modèle non linéaire !\n",
    "\n",
    "Cette idée se généralise à un nombre arbitraire de variables initiales ; on crée alors tous les _monomes_ de degré au plus $d$ de ces variables : $(x_1, x_2, \\dots, x_p)$ devient $(x_1, x_2, \\dots, x_p, x_1^2, x_1 x_2, \\dots, x_p^d)$. On parle alors de _régression polynomiale_. Nous en reparlerons dans le chapitre 9. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans scikit-learn, la classe [`PolynomialFeatures`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html) du module `preprocessing` permet de créer ces nouvelles variables, ce que nous allons faire ici pour un degré $d$=15 :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entraînement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instancier un objet permettant de créer des variables polynomiales de degré au plus 15\n",
    "polynomial_features = preprocessing.PolynomialFeatures(degree=15, include_bias=False)\n",
    "\n",
    "# Appliquer cet objet aux variables de X_train \n",
    "X_train_poly = polynomial_features.fit_transform(X_train)\n",
    "\n",
    "# Appliquer la même transformation aux données de test\n",
    "X_test_poly = polynomial_features.transform(X_test)\n",
    "\n",
    "# Ainsi qu'à la grille de points servant à appliquer le modèle sur tout [0, 1]\n",
    "X_grid_poly = polynomial_features.transform(X_grid)\n",
    "\n",
    "print(X_train_poly.shape, X_test_poly.shape, X_grid_poly.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Combien de variables avons-nous maintenant ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ Il y en a 15 : $x^1, x^2, x^3, \\dots, x^{15}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Entraîner maintenant une régression polynomiale `polyreg` sur le jeu d'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instancier une régression linéaire\n",
    "polyreg = linear_model.LinearRegression()\n",
    "\n",
    "# Entrainer cet objet sur les données d'entraînement\n",
    "polyreg.fit(X_train_poly, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Quelle est maintenant l'équation du modèle appris ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eqn_str = f\"y = {polyreg.intercept_[0]:.1e}\"\n",
    "for degree in range(15):\n",
    "    coefficient = polyreg.coef_[0][degree]\n",
    "    if coefficient > 0:\n",
    "        eqn_str += f\" + {coefficient:.1e} x^{degree+1}\"\n",
    "    else : \n",
    "        eqn_str += f\" - {-coefficient:.1e} x^{degree+1}\"\n",
    "print(eqn_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Que dire de ces coefficients ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ Les coefficients ont de très grandes amplitudes, il y a un risque de surapprentissage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__  Calculer le coefficient de détermination de la régression polynomiale sur le jeu d'entraînement et sur le jeu de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer le coefficient de détermination de polyreg sur le jeu d'entraînement\n",
    "polyreg_r2_train = metrics.r2_score(y_train, polyreg.predict(X_train_poly))\n",
    "print(f\"R2 de la régression polynomiale sur le jeu d'entraînement : {polyreg_r2_train:.2f}.\")\n",
    "\n",
    "# Calculer le coefficient de détermination de polyreg sur le jeu de test\n",
    "polyreg_r2_test = metrics.r2_score(y_test, polyreg.predict(X_test_poly))\n",
    "print(f\"R2 de la régression polynomiale sur le jeu de test : {polyreg_r2_test:.2f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Que pouvez-vous conclure sur le choix de la régression polynomiale ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ Le modèle surapprend. Les performances du jeu d'entraînement sont bien supérieures à celles du jeu de test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Remplacer sur le graphique précédent le modèle appris par régression linéaire par celui  appris par régression polynomiale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 4))\n",
    "\n",
    "# Afficher le vrai modèle\n",
    "plt.plot(X_grid, y_true, label=\"vérité\", color=\"black\", linewidth=1, linestyle='dashed')\n",
    "\n",
    "# Afficher les données simulées (entraînement)\n",
    "plt.scatter(X_train, y_train, label=\"jeu d'entraînement\", color=\"tab:blue\", marker=\"+\", s=50)\n",
    "# Afficher les données simulées (test)\n",
    "plt.scatter(X_test, y_test, label=\"jeu de test\", color=\"tab:green\", marker=\"x\", s=50)\n",
    "\n",
    "# Calculer les prédictions pour les points de X_grid\n",
    "y_polyreg = polyreg.predict(X_grid_poly)\n",
    "plt.plot(X_grid, y_polyreg, label=\"régression polynomiale\",\n",
    "         color=\"tab:orange\", linewidth=2)\n",
    "\n",
    "# Mise en forme\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"$y$\")\n",
    "plt.xlim((0, 1))\n",
    "plt.ylim((-10, 10))\n",
    "\n",
    "plt.title(\"Régression polynomiale\")\n",
    "plt.legend(loc=(1.1, 0.5))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Le graphique est-il cohérent avec les performances calculées ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ Oui, la courbe estimée colle complètement aux données d'entraînement, mais pas du tout au vrai modèle. Le modèle appris par régression polynomiale surapprend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Régression polynomiale régularisée ridge\n",
    "\n",
    "Comme la régression polynomiale surapprend, nous allons maintenant lui appliquer un terme de __régularisation ridge (L2)__ pour essayer de compenser cet effet :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entraînement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instancier une régression linéaire avec régularisation ridge avec un coefficient de régularisation valant 0.01\n",
    "polyreg_ridge = linear_model.Ridge(alpha=0.01, random_state=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Utiliser `polyreg_ridge` pour entraîner une régression polynomiale avec régularisation L2 sur le jeu d'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrainer cet objet sur les données d'entraînement\n",
    "polyreg_ridge.fit(X_train_poly, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Quelle est l'équation de ce modèle ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eqn_str = f\"y = {polyreg_ridge.intercept_[0]:.1e}\"\n",
    "for degree in range(15):\n",
    "    coefficient = polyreg_ridge.coef_[degree]\n",
    "    if coefficient > 0:\n",
    "        eqn_str += f\" + {coefficient:.1e} x^{degree+1}\"\n",
    "    else : \n",
    "        eqn_str += f\" - {-coefficient:.1e} x^{degree+1}\"\n",
    "print(eqn_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Comparer ces coefficients à ceux du modèle appris sans régularisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ La régularisation a effectivement permis de contrôler l'amplitude des coefficients du modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Calculer le coefficient de détermination de la régression polynomiale avec régularisation ridge sur le jeu d'entraînement et sur le jeu de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer le coefficient de détermination de polyreg sur le jeu d'entraînement\n",
    "polyreg_ridge_r2_train = metrics.r2_score(y_train, polyreg_ridge.predict(X_train_poly))\n",
    "print(f\"R2 de la régression polynomiale sur le jeu d'entraînement : {polyreg_ridge_r2_train:.2f}.\")\n",
    "\n",
    "# Calculer le coefficient de détermination de polyreg sur le jeu de test\n",
    "polyreg_ridge_r2_test = metrics.r2_score(y_test, polyreg_ridge.predict(X_test_poly))\n",
    "print(f\"R2 de la régression polynomiale sur le jeu de test : {polyreg_ridge_r2_test:.2f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Pensez-vous que le modèle surapprend toujours ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ Les performances sont très bonnes sur le jeu d'entraînement comme de test. Il ne semble plus y avoir de surapprentissage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Afficher maintenant ce nouveau modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "# Afficher le vrai modèle\n",
    "plt.plot(X_grid, y_true, label=\"vérité\", color=\"black\", linewidth=1, linestyle='dashed')\n",
    "\n",
    "# Afficher les données simulées (entraînement)\n",
    "plt.scatter(X_train, y_train, label=\"jeu d'entraînement\", color=\"tab:blue\", marker=\"+\", s=50)\n",
    "# Afficher les données simulées (test)\n",
    "plt.scatter(X_test, y_test, label=\"jeu de test\", color=\"tab:green\", marker=\"x\", s=50)\n",
    "\n",
    "# Calculer les prédictions pour les points de X_grid\n",
    "y_polyreg_ridge = polyreg_ridge.predict(X_grid_poly)\n",
    "plt.plot(X_grid, y_polyreg_ridge, label=\"régression polynomiale ridge (a=0.01)\",\n",
    "         color=\"tab:orange\", linewidth=2)\n",
    "\n",
    "# Mise en forme\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"$y$\")\n",
    "plt.xlim((0, 1))\n",
    "plt.ylim((-10, 10))\n",
    "\n",
    "plt.title(\"Régression polynomiale ridge\")\n",
    "plt.legend(loc=(1.1, 0.5))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Le graphique est-il cohérent avec les performances calculées ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ Oui, la courbe estimée colle bien au modèle, il ne semble pas y avoir de surapprentissage (du moins sur l'intervalle [0, 1])."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Comment aurait-on pu essayer d'éviter le surapprentissage avec une régression polynomiale mais sans régularisation ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ En utilisant un degré plus faible que 15."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Régularisation L1 (Lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Simulation de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commençons par simuler un jeu de données de 60 échantillons avec 100 variables, et dans lequel l'étiquette est une fonction linéaire de seulement 10 de ces variables, les autres étant du bruit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_samples = 60\n",
    "nb_features = 100\n",
    "\n",
    "# créer un jeu de données aux dimensions demandées à partir d'une loi normale centrée-réduite\n",
    "X = np.random.randn(nb_samples, nb_features)\n",
    "\n",
    "# créer un vecteur de coefficients nuls\n",
    "beta = np.zeros(nb_features)\n",
    "\n",
    "# créer des coefficients pour les 10 premières variables\n",
    "#   (pour faciliter la visualisation,\n",
    "#   décroissants en valeur absolue, avec alternance de signe)\n",
    "beta[:10] = [((-1) ** idx * np.exp(-idx/10)) for idx in range(10)]\n",
    "\n",
    "# créer les étiquettes\n",
    "y = np.dot(X, beta) + np.random.randn(nb_samples) * 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisons les coefficients du modèle ayant permis de simuler les données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "plt.stem(np.arange(nb_features), beta, markerfmt='o', \n",
    "         linefmt='tab:blue',\n",
    "         label='vrais coefficients')\n",
    "\n",
    "# Mise en forme\n",
    "plt.xlabel(\"Variables\")\n",
    "plt.ylabel(\"Poids\")\n",
    "plt.title(\"Modèle parcimonieux\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Séparer (`X`, `y`) en un jeu d'entraînement (`X_train`, `y_train`) et un jeu de test (`X_test`, `y_test`). Le jeu de test contiendra 30% des données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, \n",
    "                                                                    test_size=0.3, \n",
    "                                                                    random_state=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Corrélations entre les variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La difficulté pour l'apprentissage est double :\n",
    "- seule une faible proportion des variables influencent l'étiquette\n",
    "- le nombre d'observations est faible par rapport à ce nombre de variables.\n",
    "\n",
    "Un des problèmes qui apparait quand on a plus de variables que d'observations est que les variables peuvent apparaître corrélées même quand elles ne le sont pas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__  En vous inspirant de la PC3, affichez la matrice de corrélation entre les variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Calcul de la matrice de corrélation deux à deux\n",
    "df = pd.DataFrame(X_train)\n",
    "X_train_corr = df.corr()\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(X_train_corr, \n",
    "            vmin=-1, # borne inf des valeurs à afficher\n",
    "            vmax=1, # borne sup des valeurs à afficher\n",
    "            center= 0, # valeur médiane des valeurs à afficher,\n",
    "            cmap='PuOr', # colormap divergente de violet (PUrple) vers orange (ORange)\n",
    "           )\n",
    "plt.title(\"Corrélation entre les variables de X_train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Commenter cette matrice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ On observe des paires de variables assez corrélées (valeur absolue de corrélation > 0.6) alors que les variables ont été tirées indépendantes les unes des autres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Régression linéaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Entraîner sur (`X_train, y_train`) une régression linéaire classique. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instancier un objet LinearRegression\n",
    "linreg = linear_model.LinearRegression()\n",
    "\n",
    "# Entrainer cet objet sur les données d'entraînement\n",
    "linreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Évaluer la RMSE de cette régression linéaire sur le jeu d'entraînement et sur le jeu de test. La régression linéaire a-t-elle une performance satisfaisante ? Y-a-t'il un risque de sur- ou de sous-apprentissage ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_rmse_train = metrics.root_mean_squared_error(y_train, linreg.predict(X_train))\n",
    "print(f\"RMSE de la régression linéaire sur le jeu d'entraînement : {linreg_rmse_train:.2f}.\")\n",
    "\n",
    "linreg_rmse_test = metrics.root_mean_squared_error(y_test, linreg.predict(X_test))\n",
    "print(f\"RMSE de la régression linéaire sur le jeu de test : {linreg_rmse_test:.2f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ Il y a manifestement surapprentissage, la performance sur le jeu d'entraînement étant parfaite mais pas sur le jeu de test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ La performance sur le jeu d'entraînement est-elle surprenante ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ Comme il y a plus de variables que d'observations, apprendre une régression linéaire est équivalent à résoudre un système linéaire avec plus d'inconnues que d'équations : on peut toujours trouver une solution (il y en a une infinité), et donc avoir une erreur nulle sur le jeu d'entraînement.\n",
    "\n",
    "Parmi cette infinité de solutions, l'algorithme utilisé pour implémenter la méthode `fit` de `LinearRegression` en trouve une, dont il n'y a aucun moyen de garantir la performance sur le jeu de test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Ajouter à la visualisation des poids du modèle les coefficients appris par la régression linéaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "plt.stem(np.arange(nb_features), beta, markerfmt='o', \n",
    "         linefmt='tab:blue',\n",
    "         label='vrais coefficients')\n",
    "\n",
    "plt.stem(np.arange(nb_features), linreg.coef_, markerfmt='x', \n",
    "         linefmt='tab:orange',\n",
    "         label='coefficients de la régression linéaire')\n",
    "\n",
    "\n",
    "# Mise en forme\n",
    "plt.xlabel(\"Variables\")\n",
    "plt.ylabel(\"Poids\")\n",
    "plt.title(\"Modèle parcimonieux\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Comparer les coefficients appris aux vrais coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ Les poids appris pour les variables ayant des coefficients non nuls sont plus faibles que les vrais poids. Par contre, les variables qui ne devraient pas entrer dans le modèle ont des poids non nuls, parfois supérieurs (en valeur absolue) à ceux des «vraies» variables. \n",
    "\n",
    "La régression linéaire a «réparti» les coefficients sur toutes les variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Entrainez un Lasso avec comme paramètre de régularisation `alpha=0.01` sur les données d'entraînement en utilisant la classe [`Lasso`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html)  du module `linear_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instancier un objet LinearRegression\n",
    "lasso = linear_model.Lasso(alpha=0.01, random_state=13)\n",
    "\n",
    "# Entrainer cet objet sur les données d'entraînement\n",
    "lasso.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Évaluer la RMSE de ce lasso sur le jeu d'entraînement et sur le jeu de test. Y-a-t'il a un risque de sur- ou de sous-apprentissage ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_rmse_train = metrics.root_mean_squared_error(y_train, lasso.predict(X_train))\n",
    "print(f\"RMSE du lasso sur le jeu d'entraînement : {lasso_rmse_train:.2f}.\")\n",
    "\n",
    "lasso_rmse_test = metrics.root_mean_squared_error(y_test, lasso.predict(X_test))\n",
    "print(f\"RMSE du lasso sur le jeu de test : {lasso_rmse_test:.2f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ Il semble toujours y avoir du surapprentissage, mais moins que précédemment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ Comme il y a plus de variables que d'observations, apprendre une régression linéaire est équivalent à résoudre un système linéaire avec plus d'inconnues que d'équations : on peut toujours trouver une solution (il y en a une infinité), et donc avoir une erreur nulle sur le jeu d'entraînement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Ajouter à la visualisation des poids du modèle les coefficients appris par le lasso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "plt.stem(np.arange(nb_features), beta, markerfmt='o', \n",
    "         linefmt='tab:blue',\n",
    "         label='vrais coefficients')\n",
    "\n",
    "# plt.stem(np.arange(nb_features), linreg.coef_, markerfmt='x', \n",
    "#          linefmt='tab:orange',\n",
    "#          label='coefficients de la régression linéaire')\n",
    "\n",
    "plt.stem(np.arange(nb_features), lasso.coef_, markerfmt='d', \n",
    "         linefmt='tab:green',\n",
    "         label='coefficients du lasso')\n",
    "\n",
    "# Mise en forme\n",
    "plt.xlabel(\"Variables\")\n",
    "plt.ylabel(\"Poids\")\n",
    "plt.title(\"Modèle parcimonieux\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Comparer les coefficients appris aux vrais coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ De nombreux poids sont tombés à zéro. Néanmoins certains d'entre eux correspondent aux « vraies » variables, tandis que des variables que nous n'avons pas utilisées pour la simulation ont des coefficients non-nuls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sélection de modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons jusqu'à présent fixé la valeur du coefficient de régularisation (`alpha` dans `scikit-learn`, $\\lambda$ dans le poly). Nous allons maintenant voir comment utiliser une recherche sur grille dans le cadre d'une validation croisée pour _sélectionner_ la valeur de ce coefficient, qui est un _hyperparmètre_ du lasso.\n",
    "\n",
    "Nous travaillons toujours avec les données de la section 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Validation croisée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La classe `KFold` du module `model_selection` de scikit-learn permet de créer des _folds_ de validation croisée, c'est-à-dire de diviser un jeu de données en K blocs et de constituer K paires de jeux d'entraînement et de validation, où le jeu de validation est l'un des blocs et le jeu d'entraînement est l'union des (K-1) autres blocs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantier un objet KFold \n",
    "kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La méthode `kf.split()` permet maintenant de partager un jeu de données en 5 folds. Attention, elle retourne un générateur, sur lequel on ne peut itérer qu'une fois. Fixer la valeur de `random_state` permet d'avoir la même partition à chaque appel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (train_indices, val_indices) in enumerate(kf.split(X_train)):\n",
    "    print(f\"fold: {i} : {len(train_indices)} observations pour l'entraînement et {len(val_indices)} pour la validation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Compléter le code suivant pour déterminer la RMSE en validation croisée (c'est-à-dire la performance moyenne sur les 5 jeux de validation) d'un lasso avec coefficient de régularisation `alpha=0.01`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir le modèle à évaluer\n",
    "lasso = linear_model.Lasso(alpha=0.01, random_state=13)\n",
    "\n",
    "rmse_list = []\n",
    "# Boucler sur les folds :\n",
    "for i, (train_indices, val_indices) in enumerate(kf.split(X_train)):\n",
    "    print(f\"fold: {i} : {len(train_indices)} observations pour l'entraînement et {len(val_indices)} pour la validation.\")\n",
    "\n",
    "    # créer le jeu d'entraînement et le jeu de validation pour ce fold\n",
    "    X_train_fold = X_train[train_indices]\n",
    "    y_train_fold = y_train[train_indices]\n",
    "    X_test_fold = X_train[val_indices]\n",
    "    y_test_fold = y_train[val_indices]\n",
    "\n",
    "    # entraîner le modèle sur le jeu d'entraînement de ce fold\n",
    "    lasso.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    # prédire sur le jeu de validation du fold\n",
    "    rmse_fold = metrics.root_mean_squared_error(y_test_fold, lasso.predict(X_test_fold))\n",
    "    rmse_list.append(rmse_fold)\n",
    "    print(f\"\\tRMSE (test) : {rmse_fold:.2f}\")\n",
    "\n",
    "# Moyenner les performances\n",
    "rmse_average = np.mean(rmse_list)                    \n",
    "print(f\"La RMSE moyenne du Lasso (alpha=0.1) est de {rmse_average:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn peut faire cette opération directement avec la fonction `cross_validate` du module `model_selection` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_cv_scores = model_selection.cross_val_score(lasso, X_train, y_train, \n",
    "                                                  cv=kf, # utiliser les folds déjà définis \n",
    "                                                  scoring='neg_root_mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vérifions que l'on obtient bien les mêmes résultats :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lasso_cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"La RMSE moyenne du Lasso (alpha=0.01) est de {-np.mean(lasso_cv_scores):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Pourquoi est-ce `neg_root_mean_squared_error`, qui retourne _l'opposé_ de la RMSE, qui est implémentée comme fonction de score et non pas directement la RMSE ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ Ces scores sont utilisés pour sélectionner le meilleur modèle, qui sera celui qui a le score de performance le plus élevé. Dans le cas de la RMSE, il s'agit donc de celui qui a la plus petite RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Recherche sur grille"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La _recherche sur grille_ (_gridsearch_) consiste à comparer différentes valeurs d'une grille d'hyperparamètres en comparant la performance des modèles appris avec chacune de ces valeurs, généralement en utilisant une validation croisée.\n",
    "\n",
    "Dans scikit-learn, cette procédure est implémentée dans la classe `GridSearchCV` de `model_selection` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir la grille de valeurs de l'hyperparamètre alpha \n",
    "alphas = np.logspace(-5, 1, 40)\n",
    "\n",
    "# Définir le modèle à évaluer\n",
    "lasso = linear_model.Lasso(random_state=13, \n",
    "                           max_iter=10000 # pour assurer la convergence (warning sinon)\n",
    "                          )\n",
    "\n",
    "# Instantier la recherche sur grille\n",
    "grid = model_selection.GridSearchCV(lasso, {'alpha': alphas}, \n",
    "                                    cv=kf, # on utilise les folds déjà définis\n",
    "                                    scoring='neg_root_mean_squared_error'\n",
    "                                   )\n",
    "\n",
    "# Utiliser la recherche sur grille\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Valeur de la RMSE en fonction de alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les détails des calculs effectués par `fit` sont accessibles dans le dictionnaire retourné par `grid.cv_results_` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.cv_results_.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut ainsi récupérer les scores obtenus pour chaque valeur de `alpha` et les représenter sur une figure :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "rmses = -grid.cv_results_['mean_test_score']\n",
    "std_error = grid.cv_results_['std_test_score']\n",
    "\n",
    "# afficher les RMSE avec une échelle logarithmique pour les abscisses :\n",
    "plt.semilogx(grid.cv_results_['param_alpha'], rmses, \n",
    "             label=\"lasso\", color='tab:blue')\n",
    "plt.semilogx(grid.cv_results_['param_alpha'], rmses + std_error, \n",
    "             color='tab:blue', linestyle='dashed')\n",
    "plt.semilogx(grid.cv_results_['param_alpha'], rmses - std_error, \n",
    "             color='tab:blue', linestyle='dashed')\n",
    "\n",
    "# colorer l'espace entre les courbes représentant les écarts-types\n",
    "plt.fill_between(alphas, (rmses + std_error), (rmses - std_error), \n",
    "                 color='tab:blue',\n",
    "                 alpha=0.2, # contrôle la transparence\n",
    "                )\n",
    "\n",
    "# Mise en forme\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"RMSE +/- un écart-type\")\n",
    "plt.xlim([alphas[0], alphas[-1]])\n",
    "plt.title(\"Recherche sur grille (Lasso)\")\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ À quoi correspond un modèle avec une faible valeur de `alpha` ? Une valeur élevée de `alpha` ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ Quand `alpha` tend vers 0, on se rapproche d'une régression linéaire non régularisée. Quand `alpha` est suffisamment grand, le risque empirique ne compte plus devant le terme de régularisation, et le lasso apprend un modèle dans lequel tous les poids sont nuls.\n",
    "\n",
    "Dans les deux cas, c'est parce qu'on a atteint ces comportements que l'on observe un plateau de la RMSE à droite et à gauche de la figure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Remarque :__ La performance du Lasso avec un coefficient de régularisation très faible est meilleure que celle de la régression linéaire. Il s'agit du même problème d'optimisation, mais l'algorithme d'optimisation utilisé pour le résoudre n'est pas le même dans les deux cas. Rappelons que le problème de minimisation du risque empirique de la régression linéaire admet une infinité de solutions ; dans le cas où le nombre de variables est inférieur au nombre d'observations, les deux solutions (régression linéaire et lasso avec coefficient de régularisation très faible) seront identiques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Meilleur modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les valeurs optimales de la recherche sur grille et le score correspondant sont données par les paramètres`best_params_` et `best_score_` de l'objet de la classe `GridSearchCV` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"La meilleure valeur de alpha est : {grid.best_params_['alpha']:.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Afficher ce point sur la courbe précédente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize plot frame\n",
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "rmses = -grid.cv_results_['mean_test_score']\n",
    "std_error = grid.cv_results_['std_test_score']\n",
    "\n",
    "# afficher les RMSE avec une échelle logarithmique pour les abscisses :\n",
    "plt.semilogx(alphas, rmses, label=\"lasso\", color='tab:blue')\n",
    "plt.semilogx(alphas, rmses + std_error, color='tab:blue', linestyle='dashed')\n",
    "plt.semilogx(alphas, rmses - std_error, color='tab:blue', linestyle='dashed')\n",
    "\n",
    "# colorer l'espace entre les courbes représentant les écarts-types\n",
    "plt.fill_between(alphas, (rmses + std_error), (rmses - std_error), \n",
    "                 alpha=0.2 # contrôle la transparence\n",
    "                )\n",
    "\n",
    "# afficher le meilleur score\n",
    "plt.scatter(grid.best_params_['alpha'], -grid.best_score_, \n",
    "           color='tab:red', label='RMSE optimale')\n",
    "\n",
    "# Mise en forme\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"RMSE +/- un écart-type\")\n",
    "plt.xlim([alphas[0], alphas[-1]])\n",
    "plt.title(\"Recherche sur grille (Lasso)\")\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Le modèle correspondant, ré-entraîné sur l'ensemble des données passées à la fonction `fit`, est donné par le paramètre `best_estimator_`. Comparez sur une figure ses coefficients à ceux du vrai modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "plt.stem(np.arange(nb_features), beta, markerfmt='o', \n",
    "         linefmt='tab:blue',\n",
    "         label='vrais coefficients')\n",
    "\n",
    "# plt.stem(np.arange(nb_features), linreg.coef_, markerfmt='x', \n",
    "#           linefmt='tab:orange',\n",
    "#           label='coefficients de la régression linéaire')\n",
    "\n",
    "plt.stem(np.arange(nb_features), grid.best_estimator_.coef_, markerfmt='*', \n",
    "         linefmt='tab:brown',\n",
    "         label='coefficients du meilleur lasso')\n",
    "\n",
    "# Mise en forme\n",
    "plt.xlabel(\"Variables\")\n",
    "plt.ylabel(\"Poids\")\n",
    "plt.title(\"Modèle parcimonieux\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ Les coefficients appris s'approchent beaucoup des vrais coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Données réelles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour ce cas pratique nous utilisons des données cliniques. L'objectif est de **prédire le niveau d'antigène prostatique spécifique** (ou *PSA* pour *Prostate-Specific Antigen*). C'est une protéine produite exclusivement par la prostate. Un taux de concentration élevé de cette molécule dans le sang est souvent le signe chez l'homme d'un cancer de la prostate. Cet indicateur permet ainsi de suivre l'évolution d'un tel cancer.\n",
    "\n",
    "Plus précisément, nous allons essayer de prédire le niveau de concentration du *PSA* (`lpsa`, en échelle logarithmique) à partir des mesures cliniques suivantes :\n",
    "- `cavol` : Le volume de la tumeur (échelle logarithmique).\n",
    "- `lweight` : Le poids de la prostate (échelle logarithmique).\n",
    "- `age`: L'âge du patient.\n",
    "- `lbph`: Le volume de l'hypertrophie bénigne de la prostate (*BPH* pour *Benign Prostatic Hyperplasia*) qui correspond au volume non cancéreux de l'organe (échelle logarithmique).\n",
    "- `svi`: Indicateur sur le fait que le cancer s'est propagé aux vésicules séminales (deux glandes associées à la prostate).\n",
    "- `lcp`: La *pénétration capsulaire* qui mesure à quel point la capsule prostatique (la membrane qui entoure la prostate), a été envahi par le cancer (échelle logarithmique).\n",
    "- `gleason`: Le score de *Gleason*. Ce score est établi par un histopathologiste après observation d'une biopsie de la prostate. Pour plus d'information vous pouvez consulter ce lien : http://www.wikiwand.com/en/Gleason_grading_system. \n",
    "* `pgg45`: Le pourcentage de la tumeur qui est accrédité d'un score *Gleason* de 4 ou 5.\n",
    "\n",
    "Ce jeu de données est un jeu de données classique, que l'on trouve par exemple [sur Kaggle](https://www.kaggle.com/tvscitechtalk/prostatecsv). Il est issu de Stamey, T.A., Kabalin, J.N., McNeal, J.E., Johnstone, I.M., Freiha, F., Redwine, E.A. and Yang, N. (1989). Prostate specific antigen in the diagnosis and treatment of adenocarcinoma of the prostate: II. radical prostatectomy treated patients, _Journal of Urology_ 141(5), 1076–1083.\n",
    "\n",
    "Nous avons bien ici un problème de **régression**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/prostate.csv\", index_col=0)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons extraire de ce dataframe une matrice `X` de données et un vecteur `y` d'étiquettes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:, [\"lcavol\", \"lweight\", \"age\", \"lbph\", \"svi\", \"lcp\", \"gleason\", \"pgg45\"]].to_numpy()\n",
    "y = df.loc[:, \"lpsa\"].to_numpy()\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jeu d'entraînement et de test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Séparer ce jeu de données en un jeu d'entraînement et un jeu de test (contenant 30% des observations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset for train and test\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, \n",
    "                                                                    test_size=0.3, random_state=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformation des variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ En vous inspirant de la PC4, centrez et réduisez les variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Régression linéaire non régularisée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Calculer la RMSE d'une régression linéaire en validation croisée sur le jeu d'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instancier un objet LinearRegression\n",
    "linreg = linear_model.LinearRegression()\n",
    "\n",
    "# Utiliser une validation croisée à 5 folds\n",
    "linreg_cv_scores = model_selection.cross_val_score(linreg, X_train_scaled, y_train, \n",
    "                                                   cv=5,  \n",
    "                                                   scoring='neg_root_mean_squared_error')\n",
    "linreg_cv_scores = -linreg_cv_scores\n",
    "\n",
    "print(f\"La RMSE moyenne de la régression linéaire est de {np.mean(linreg_cv_scores):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Régression ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ En utilisant une validation croisée sur le jeu d'entraînement, effectuez une recherche sur une grille de valeurs entre $10^{-3}$ et $10^5$ du meilleur coefficient de régularisation pour une régression ridge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir la grille de valeurs de l'hyperparamètre alpha \n",
    "alphas = np.logspace(-3, 5, 40)\n",
    "\n",
    "# Définir le modèle à tester\n",
    "ridge = linear_model.Ridge(random_state=25)\n",
    "\n",
    "# Instantier la recherche sur grille\n",
    "grid_ridge = model_selection.GridSearchCV(ridge, {'alpha': alphas}, \n",
    "                                          cv=5, # on demande à définir 5 folds\n",
    "                                          scoring='neg_root_mean_squared_error'\n",
    "                                         )\n",
    "\n",
    "# Utiliser la recherche sur grille\n",
    "grid_ridge.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Quelle est la valeur optimale de RMSE obtenue ? Pour quelle valeur de coefficient de régularisation ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Meileure RMSE (régresion ridge, alpha={grid_ridge.best_params_['alpha']:.2e}) : {-grid_ridge.best_score_:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Afficher l'évolution de la RMSE en fonction de la valeur du coefficient de régularisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize plot frame\n",
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "rmses = -grid_ridge.cv_results_['mean_test_score']\n",
    "std_error = grid_ridge.cv_results_['std_test_score']\n",
    "\n",
    "# afficher les RMSE avec une échelle logarithmique pour les abscisses :\n",
    "plt.semilogx(alphas, rmses, label=\"ridge\", color='tab:blue')\n",
    "plt.semilogx(alphas, rmses + std_error, color='tab:blue', linestyle='dashed')\n",
    "plt.semilogx(alphas, rmses - std_error, color='tab:blue', linestyle='dashed')\n",
    "\n",
    "# colorer l'espace entre les courbes représentant les écarts-types\n",
    "plt.fill_between(alphas, (rmses + std_error), (rmses - std_error), \n",
    "                 alpha=0.2 # contrôle la transparence\n",
    "                )\n",
    "\n",
    "# afficher le meilleur score\n",
    "plt.scatter(grid_ridge.best_params_['alpha'], -grid_ridge.best_score_, \n",
    "           color='tab:red', label='RMSE optimale')\n",
    "\n",
    "# Mise en forme\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"RMSE +/- un écart-type\")\n",
    "plt.xlim([alphas[0], alphas[-1]])\n",
    "plt.title(\"Recherche sur grille (Ridge)\")\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Afficher les coefficients de la meilleure régression ridge. Quelles variables paraissent plus pertinentes pour la prédiction ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 3))\n",
    "\n",
    "nb_features = X_train_scaled.shape[1]\n",
    "plt.stem(np.arange(nb_features), grid_ridge.best_estimator_.coef_, markerfmt='*', \n",
    "         linefmt='tab:blue',\n",
    "         label='meilleure régression ridge')\n",
    "\n",
    "# Mise en forme\n",
    "plt.xlabel(\"Variables\")\n",
    "plt.ylabel(\"Poids\")\n",
    "plt.xticks(np.arange(nb_features), \n",
    "           labels=list(df.columns[:-1]))\n",
    "plt.title(\"Modèles prédictifs du PSA\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ Les variables les plus pertinentes semblent être `lcavol`, `lweight` et `svi`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ En utilisant une validation croisée sur le jeu d'entraînement, effectuez une recherche sur une grille de valeurs entre $10^{-4}$ et $10^2$ du meilleur coefficient de régularisation pour un lasso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir la grille de valeurs de l'hyperparamètre alpha \n",
    "alphas = np.logspace(-4, 2, 40)\n",
    "\n",
    "# Définir le modèle à tester\n",
    "lasso = linear_model.Lasso(random_state=25)\n",
    "\n",
    "# Instantier la recherche sur grille\n",
    "grid_lasso = model_selection.GridSearchCV(lasso, {'alpha': alphas}, \n",
    "                                          cv=5, \n",
    "                                          scoring='neg_root_mean_squared_error'\n",
    "                                         )\n",
    "\n",
    "# Utiliser la recherche sur grille\n",
    "grid_lasso.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Quelle est la valeur optimale de RMSE obtenue ? Pour quelle valeur de coefficient de régularisation ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Meileure RMSE (lasso, alpha={grid_lasso.best_params_['alpha']:.2e}) : {-grid_lasso.best_score_:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Afficher l'évolution de la RMSE en fonction de la valeur du coefficient de régularisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "rmses = -grid_lasso.cv_results_['mean_test_score']\n",
    "std_error = grid_lasso.cv_results_['std_test_score']\n",
    "\n",
    "# afficher les RMSE avec une échelle logarithmique pour les abscisses :\n",
    "plt.semilogx(alphas, rmses, label=\"lasso\", color='tab:blue')\n",
    "plt.semilogx(alphas, rmses + std_error, color='tab:blue', linestyle='dashed')\n",
    "plt.semilogx(alphas, rmses - std_error, color='tab:blue', linestyle='dashed')\n",
    "\n",
    "# colorer l'espace entre les courbes représentant les écarts-types\n",
    "plt.fill_between(alphas, (rmses + std_error), (rmses - std_error), \n",
    "                 alpha=0.2 # contrôle la transparence\n",
    "                )\n",
    "\n",
    "# afficher le meilleur score\n",
    "plt.scatter(grid_lasso.best_params_['alpha'], -grid_lasso.best_score_, \n",
    "           color='tab:red', label='RMSE optimale')\n",
    "\n",
    "# Mise en forme\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"RMSE +/- un écart-type\")\n",
    "plt.xlim([alphas[0], alphas[-1]])\n",
    "plt.title(\"Recherche sur grille (Lasso)\")\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Afficher sur le même graphique les coefficients de la meilleure régression ridge et ceux du meilleur lasso. Quelles variables paraissent plus pertinentes pour la prédiction ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 3))\n",
    "\n",
    "nb_features = X_train_scaled.shape[1]\n",
    "plt.stem(np.arange(nb_features), grid_ridge.best_estimator_.coef_, markerfmt='*', \n",
    "         linefmt='tab:blue',\n",
    "         label='coefficients de la meilleure régression ridge')\n",
    "\n",
    "nb_features = X_train_scaled.shape[1]\n",
    "plt.stem(np.arange(nb_features), grid_lasso.best_estimator_.coef_, markerfmt='*', \n",
    "         linefmt='tab:orange',\n",
    "         label='coefficients du meilleur lasso')\n",
    "\n",
    "# Mise en forme\n",
    "plt.xlabel(\"Variables\")\n",
    "plt.ylabel(\"Poids\")\n",
    "plt.xticks(np.arange(nb_features), \n",
    "           labels=list(df.columns[:-1]))\n",
    "plt.title(\"PSA\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Comparer ces deux modèles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ Les deux sont très similaires. Néanmoins le Lasso a une performance légèrement supérieure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Quel est le meilleur modèle ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ Le lasso avec un coefficient de régularisation de 0.03."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Quelle performance peut-on espérer de ce modèle sur de nouvelles données ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ C'est le moment d'utiliser le jeu de test :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_lasso.best_estimator_.predict(X_test_scaled) \n",
    "rmse_test = metrics.root_mean_squared_error(y_test, y_pred)\n",
    "print(f\"La RMSE de ce Lasso sur le jeu de test est de {rmse_test:.2f}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
